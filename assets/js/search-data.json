{
  
    
        "post0": {
            "title": "Metrics Video2 Constants For Mse And Mae",
            "content": "“This document briefly explains why target mean value minimizes MSE error and why target median minimizes MAE” . Suppose we have a dataset {(xi,yi)}i=1N {(x_i,y_i) }_{i=1}^N{(xi​,yi​)}i=1N​ . Basically, we are given pairs: features $x_i$ and corresponding target value $y_i in mathbb{R}$. . We will denote vector of targets as $y in mathbb{R}^N$, such that $y_i$ is target for object $x_i$. Similarly, $ hat y in mathbb{R}$ denotes predictions for the objects: $ hat y_i$ for object $x_i$. . MSE . Let’s start with MSE loss. It is defined as follows: . MSE(y,y^)=1N∑i=1N(y^i−yi)2MSE(y, hat y) = frac{1}{N} sum_{i=1}^N ( hat y_i - y_i)^2MSE(y,y^​)=N1​i=1∑N​(y^​i​−yi​)2 . Now, the question is: if predictions for all the objects were the same and equal to $ alpha$: $ hat y_i = alpha$, what value of $ alpha$ would minimize MSE error? . min⁡αf(α)=1N∑i=1N(α−yi)2 min_{ alpha} f( alpha) = frac{1}{N} sum_{i=1}^N ( alpha - y_i)^2αmin​f(α)=N1​i=1∑N​(α−yi​)2 . The function $f( alpha)$, that we want to minimize is smooth with respect to $ alpha$. A required condition for $ alpha^*$ to be a local optima is dfdα∣α=α∗=0 . frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = 0 , .dαdf​∣∣​α=α∗​=0. . Let’s find the points, that satisfy the condition: . dfdα∣α=α∗=2N∑i=1N(α∗−yi)=0 frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = frac{2}{N} sum_{i=1}^N ( alpha^* - y_i) = 0dαdf​∣ . ∣​α=α∗​=N2​i=1∑N​(α∗−yi​)=0 . 2N∑i=1Nα∗−2N∑i=1Nyi=0 frac{2}{N} sum_{i=1}^N alpha^* - frac{2}{N} sum_{i=1}^N y_i = 0N2​i=1∑N​α∗−N2​i=1∑N​yi​=0 . α∗−1N∑i=1Nyi=0 alpha^* - frac{1}{N} sum_{i=1}^N y_i = 0α∗−N1​i=1∑N​yi​=0 . And finally: α∗=1N∑i=1Nyi alpha^* = frac{1}{N} sum_{i=1}^N y_iα∗=N1​∑i=1N​yi​ . Since second derivative $ frac{d^2 f}{d alpha^2}$ is positive at point $ alpha^*$, then what we found is local minima. . So, that is how it is possible to find, that optial constan for MSE metric is target mean value. . MAE . Similarly to the way we found optimal constant for MSE loss, we can find it for MAE. . MAE(y,y^)=1N∑i=1N∣y^i−yi∣MAE(y, hat y) = frac{1}{N} sum_{i=1}^N | hat y_i - y_i|MAE(y,y^​)=N1​i=1∑N​∣y^​i​−yi​∣ . min⁡αf(α)=1N∑i=1N∣α−yi∣ min_{ alpha} f( alpha) = frac{1}{N} sum_{i=1}^N | alpha - y_i|αmin​f(α)=N1​i=1∑N​∣α−yi​∣ . Recall that $ frac{ partial | x | }{dx} = sign(x)$, where $sign$ stands for signum function . Thus | . dfdα∣α=α∗=1N∑i=1Nsign(α∗−yi)=0 frac{d f}{d alpha} bigg|_{ alpha= alpha^*} = frac{1}{N} sum_{i=1}^N sign( alpha^* - y_i) = 0dαdf​∣ . ∣​α=α∗​=N1​i=1∑N​sign(α∗−yi​)=0 . So we need to find such $ alpha^*$ that . g(α∗)=∑i=1Nsign(α∗−yi)=0g( alpha^*) = sum_{i=1}^N sign( alpha^* - y_i) = 0g(α∗)=i=1∑N​sign(α∗−yi​)=0 . Note that $g( alpha^)$ is piecewise-constant non-decreasing function. $g( alpha^)=-1$ for all calues of $ alpha$ less then mimimum $y_i$ and $g( alpha^*)=1$ for $ alpha &gt; max_i y_i$. The function “jumps” by $ frac{2}{N}$ at every point $y_i$. Here is an example, how this function looks like for $y = [-0.5, 0, 1, 3, 3.4]$: . . Basically there are $N$ jumps of the same size, starting from $-1$ and ending at $1$. It is clear, that you need to do about $ frac{N}{2}$ jumps to hit zero. And that happens exactly at median value of the target vector $g(median(y))=0$. We should be careful and separate two cases: when there are even number of points and odd, but the intuition remains the same. . .",
            "url": "https://naiborhujosua.github.io/mlnotes_josua/2022/04/01/Metrics-video2-constants-for-MSE-and-MAE.html",
            "relUrl": "/2022/04/01/Metrics-video2-constants-for-MSE-and-MAE.html",
            "date": " • Apr 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Z-unlock Challenge: Data Visualization",
            "content": "We will Analyze the correlation of temperatures changes on energy use, land cover,waste use and deforestoration by questioning these questions. . What are the areas with biggest/smallest change in temperature? | Are there any correlations between the hottest changes and other phenomena (like land coverage, land fires, CO2 emissions etc.) | How does the seasonal temperature change look like? | How does this vary by continent? Particularly South America? | . # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): for filename in filenames: print(os.path.join(dirname, filename)) # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won&#39;t be saved outside of the current session . /kaggle/input/z-unlocked-challenge-1-data-visualization/waste_disposal_data_11-29-2021.csv /kaggle/input/z-unlocked-challenge-1-data-visualization/land_cover_data_11-30-2021.csv /kaggle/input/z-unlocked-challenge-1-data-visualization/temperature_change_data_11-29-2021.csv /kaggle/input/z-unlocked-challenge-1-data-visualization/energy_use_data_11-29-2021.csv /kaggle/input/z-unlocked-challenge-1-data-visualization/fires_data_11-29-2021.csv . import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import warnings warnings.filterwarnings(&quot;ignore&quot;) . df_temperature = pd.read_csv(&quot;/kaggle/input/z-unlocked-challenge-1-data-visualization/temperature_change_data_11-29-2021.csv&quot;) df_temperature.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Months Code Months Year Code Year Unit Value Flag Flag Description . 0 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1961 | 1961 | °C | -0.751 | Fc | Calculated data | . 1 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1962 | 1962 | °C | 0.985 | Fc | Calculated data | . 2 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1963 | 1963 | °C | 1.931 | Fc | Calculated data | . 3 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1964 | 1964 | °C | -2.056 | Fc | Calculated data | . 4 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1965 | 1965 | °C | -0.669 | Fc | Calculated data | . temp_max = df_temperature.groupby(&quot;Area&quot;)[&quot;Value&quot;].max().sort_values(ascending=False).reset_index() temp_min = df_temperature.groupby(&quot;Area&quot;)[&quot;Value&quot;].min().sort_values().reset_index() d2 = temp_max[:5] plt.figure(figsize=(10, 7)) plt.bar(d2[&#39;Area&#39;], d2[&#39;Value&#39;], width=0.3) for i, val in enumerate(d2[&#39;Value&#39;].values): plt.text(i, val, round(float(val)), horizontalalignment=&#39;center&#39;, verticalalignment=&#39;bottom&#39;, fontdict={&#39;fontweight&#39;:500, &#39;size&#39;: 16}) plt.gca().set_xticklabels(d2[&#39;Area&#39;], fontdict={&#39;size&#39;: 14},rotation=60) plt.title(&quot;Max temperature Change for top 5 Area&quot;, fontsize=22) plt.ylabel(&quot;Temperature&quot;, fontsize=16) plt.xlabel(&quot;Area&quot;, fontsize=16) plt.show() . d2 = temp_min[:5] plt.figure(figsize=(10, 7)) plt.bar(d2[&#39;Area&#39;], d2[&#39;Value&#39;], width=0.3) for i, val in enumerate(d2[&#39;Value&#39;].values): plt.text(i, val, round(float(val)), horizontalalignment=&#39;center&#39;, verticalalignment=&#39;bottom&#39;, fontdict={&#39;fontweight&#39;:500, &#39;size&#39;: 16}) plt.gca().set_xticklabels(d2[&#39;Area&#39;], fontdict={&#39;size&#39;: 14},rotation=60) plt.title(&quot;Min temperature Change for top 5 Area&quot;, fontsize=22) plt.ylabel(&quot;Temperature&quot;, fontsize=16) plt.xlabel(&quot;Area&quot;, fontsize=16) plt.show() . Biggest/smallest change in temperature: . Svalbard and Jan Mayeb Island is the most change in temperature based on the chart above | . Are there any correlations between the hottest changes and other phenomena (like land coverage, land fires, CO2 emissions etc.) . Look at all the possibilities from another dataset/tables | . energy_df = pd.read_csv(&quot;/kaggle/input/z-unlocked-challenge-1-data-visualization/energy_use_data_11-29-2021.csv&quot;) energy_df.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Item Code Item Year Code Year Unit Value Flag Flag Description . 0 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1990 | 1990 | kilotonnes | 231.4918 | F | FAO estimate | . 1 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1991 | 1991 | kilotonnes | 188.5317 | F | FAO estimate | . 2 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1992 | 1992 | kilotonnes | 47.9904 | F | FAO estimate | . 3 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1993 | 1993 | kilotonnes | 38.6116 | F | FAO estimate | . 4 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1994 | 1994 | kilotonnes | 31.4465 | F | FAO estimate | . land_df = pd.read_csv(&quot;/kaggle/input/z-unlocked-challenge-1-data-visualization/land_cover_data_11-30-2021.csv&quot;) land_df.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Item Code Item Year Code Year Unit Value Flag Flag Description . 0 LC | Land Cover | AFG | Afghanistan | 5007 | Area from MODIS | 6970 | Artificial surfaces (including urban and assoc... | 2001 | 2001 | 1000 ha | 88.1603 | FC | Calculated data | . 1 LC | Land Cover | AFG | Afghanistan | 5007 | Area from MODIS | 6970 | Artificial surfaces (including urban and assoc... | 2002 | 2002 | 1000 ha | 88.1818 | FC | Calculated data | . 2 LC | Land Cover | AFG | Afghanistan | 5007 | Area from MODIS | 6970 | Artificial surfaces (including urban and assoc... | 2003 | 2003 | 1000 ha | 88.2247 | FC | Calculated data | . 3 LC | Land Cover | AFG | Afghanistan | 5007 | Area from MODIS | 6970 | Artificial surfaces (including urban and assoc... | 2004 | 2004 | 1000 ha | 88.2462 | FC | Calculated data | . 4 LC | Land Cover | AFG | Afghanistan | 5007 | Area from MODIS | 6970 | Artificial surfaces (including urban and assoc... | 2005 | 2005 | 1000 ha | 88.3106 | FC | Calculated data | . energy_df = pd.read_csv(&quot;/kaggle/input/z-unlocked-challenge-1-data-visualization/energy_use_data_11-29-2021.csv&quot;) energy_df.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Item Code Item Year Code Year Unit Value Flag Flag Description . 0 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1990 | 1990 | kilotonnes | 231.4918 | F | FAO estimate | . 1 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1991 | 1991 | kilotonnes | 188.5317 | F | FAO estimate | . 2 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1992 | 1992 | kilotonnes | 47.9904 | F | FAO estimate | . 3 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1993 | 1993 | kilotonnes | 38.6116 | F | FAO estimate | . 4 GN | Energy Use | AFG | Afghanistan | 7273 | Emissions (CO2) | 6801 | Gas-Diesel oil | 1994 | 1994 | kilotonnes | 31.4465 | F | FAO estimate | . df_temperature.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Months Code Months Year Code Year Unit Value Flag Flag Description . 0 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1961 | 1961 | °C | -0.751 | Fc | Calculated data | . 1 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1962 | 1962 | °C | 0.985 | Fc | Calculated data | . 2 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1963 | 1963 | °C | 1.931 | Fc | Calculated data | . 3 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1964 | 1964 | °C | -2.056 | Fc | Calculated data | . 4 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1965 | 1965 | °C | -0.669 | Fc | Calculated data | . waste_df = pd.read_csv(&quot;/kaggle/input/z-unlocked-challenge-1-data-visualization/waste_disposal_data_11-29-2021.csv&quot;) waste_df.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Item Code Item Year Code Year Unit Value Flag Flag Description . 0 GW | Waste Disposal | AFG | Afghanistan | 7273 | Emissions (CO2) | 6990 | Incineration | 1990 | 1990 | kilotonnes | 0.0 | Fc | Calculated data | . 1 GW | Waste Disposal | AFG | Afghanistan | 7273 | Emissions (CO2) | 6990 | Incineration | 1991 | 1991 | kilotonnes | 0.0 | Fc | Calculated data | . 2 GW | Waste Disposal | AFG | Afghanistan | 7273 | Emissions (CO2) | 6990 | Incineration | 1992 | 1992 | kilotonnes | 0.0 | Fc | Calculated data | . 3 GW | Waste Disposal | AFG | Afghanistan | 7273 | Emissions (CO2) | 6990 | Incineration | 1993 | 1993 | kilotonnes | 0.0 | Fc | Calculated data | . 4 GW | Waste Disposal | AFG | Afghanistan | 7273 | Emissions (CO2) | 6990 | Incineration | 1994 | 1994 | kilotonnes | 0.0 | Fc | Calculated data | . fires_df = pd.read_csv(&quot;/kaggle/input/z-unlocked-challenge-1-data-visualization/fires_data_11-29-2021.csv&quot;) fires_df.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Item Code Item Year Code Year Source Code Source Unit Value Flag Flag Description Note . 0 GI | Fires | AFG | Afghanistan | 7246 | Burned Area | 6796 | Humid tropical forest | 1990 | 1990 | 3050 | FAO TIER 1 | ha | 0.0 | Fc | Calculated data | NaN | . 1 GI | Fires | AFG | Afghanistan | 7246 | Burned Area | 6796 | Humid tropical forest | 1991 | 1991 | 3050 | FAO TIER 1 | ha | 0.0 | Fc | Calculated data | NaN | . 2 GI | Fires | AFG | Afghanistan | 7246 | Burned Area | 6796 | Humid tropical forest | 1992 | 1992 | 3050 | FAO TIER 1 | ha | 0.0 | Fc | Calculated data | NaN | . 3 GI | Fires | AFG | Afghanistan | 7246 | Burned Area | 6796 | Humid tropical forest | 1993 | 1993 | 3050 | FAO TIER 1 | ha | 0.0 | Fc | Calculated data | NaN | . 4 GI | Fires | AFG | Afghanistan | 7246 | Burned Area | 6796 | Humid tropical forest | 1994 | 1994 | 3050 | FAO TIER 1 | ha | 0.0 | Fc | Calculated data | NaN | . temp_change= df_temperature.groupby([&quot;Year&quot;,&quot;Months&quot;])[&quot;Value&quot;].mean().reset_index() plt.figure(figsize=(15, 10)) ax = sns.scatterplot(x=&#39;Year&#39;, y=&#39;Value&#39;, hue=&#39;Months&#39;, legend=&#39;full&#39;, data=temp_change, palette=sns.color_palette(&quot;Set1&quot;, n_colors=len(temp_change.Months.unique()))) max_value_per_year = temp_change.groupby(&#39;Year&#39;)[&#39;Value&#39;].max() sns.lineplot(data=max_value_per_year, ax=ax.axes, color=&#39;black&#39;) plt.ylabel(&quot;Temperature&quot;, fontsize=16) plt.xlabel(&quot;Year&quot;, fontsize=16) plt.title(&quot;The trend for temperature change annually over Months&quot;) plt.axvspan(2015, 2020,alpha=0.15) plt.show() . land_cover= land_df.groupby([&quot;Year&quot;])[&quot;Value&quot;].mean().reset_index() plt.figure(figsize=(15, 10)) ax = sns.scatterplot(x=&#39;Year&#39;, y=&#39;Value&#39;, legend=&#39;full&#39;, data=land_cover, palette=sns.color_palette(&quot;Set1&quot;, n_colors=len(land_cover.Year.unique()))) max_value_per_year = land_cover.groupby(&#39;Year&#39;)[&#39;Value&#39;].max() sns.lineplot(data=max_value_per_year, ax=ax.axes, color=&#39;black&#39;) plt.ylabel(&quot;Land Cover&quot;, fontsize=16) plt.xlabel(&quot;Year&quot;, fontsize=16) plt.axvspan(2004, 2006,alpha=0.15) plt.show() . energy_use= energy_df.groupby([&quot;Year&quot;])[&quot;Value&quot;].mean().reset_index() plt.figure(figsize=(15, 10)) ax = sns.scatterplot(x=&#39;Year&#39;, y=&#39;Value&#39;, legend=&#39;full&#39;, data=energy_use, palette=sns.color_palette(&quot;Set1&quot;, n_colors=len(energy_use.Year.unique()))) max_value_per_year = energy_use.groupby(&#39;Year&#39;)[&#39;Value&#39;].max() sns.lineplot(data=max_value_per_year, ax=ax.axes, color=&#39;black&#39;) plt.ylabel(&quot;Energy Use&quot;, fontsize=16) plt.xlabel(&quot;Year&quot;, fontsize=16) plt.axvspan(1985, 1989,alpha=0.15) plt.show() . waste_use= waste_df.groupby([&quot;Year&quot;])[&quot;Value&quot;].mean().reset_index() plt.figure(figsize=(15, 10)) ax = sns.scatterplot(x=&#39;Year&#39;, y=&#39;Value&#39;, legend=&#39;full&#39;, data=waste_use, palette=sns.color_palette(&quot;Set1&quot;, n_colors=len(waste_use.Year.unique()))) max_value_per_year = waste_use.groupby(&#39;Year&#39;)[&#39;Value&#39;].max() sns.lineplot(data=max_value_per_year, ax=ax.axes, color=&#39;black&#39;) plt.ylabel(&quot;Waste Use&quot;, fontsize=16) plt.xlabel(&quot;Year&quot;, fontsize=16) plt.axvspan(1990, 1993,alpha=0.15) plt.show() . fires_use= fires_df.groupby([&quot;Year&quot;])[&quot;Value&quot;].mean().reset_index() plt.figure(figsize=(15, 10)) ax = sns.scatterplot(x=&#39;Year&#39;, y=&#39;Value&#39;, legend=&#39;full&#39;, data=fires_use, palette=sns.color_palette(&quot;Set1&quot;, n_colors=len(fires_use.Year.unique()))) max_value_per_year = fires_use.groupby(&#39;Year&#39;)[&#39;Value&#39;].max() sns.lineplot(data=max_value_per_year, ax=ax.axes, color=&#39;black&#39;) plt.ylabel(&quot;Fires Use&quot;, fontsize=16) plt.xlabel(&quot;Year&quot;, fontsize=16) plt.axvspan(1999, 2003,alpha=0.15) plt.show() . Correlations between the hottest changes and other phenomena (like land coverage, land fires, CO2 emissions and Fires.) . Insight Based on Aggregating the mean per year shows correlation among temperature, energy use, land cover, waste use, and fires. All country-Value indicator(Value feature based on each tables) combinations show an increase, but there are subtle differences: . In Land cover use, in 2004-2005, there was a signifant increase followed by a slighly increase in from 2011-2017. | In Energy use, in 1985-1989, there was a signifant increase followed by a slighly increase in from 2019-2020. | In Waste use, in 1999-1993, there was a signifant drop followed by a significant increase from 1994-2020. | In Fires use, in 1990-2003, there was a signifant increase followed by a slighly decrease from 2003-2020. . | Almost everywhere, the end-of-year show an correlation that the the temperature that increase yearly affect the use of waste, energy,deforestoration, and land cover yearly. . | . How does the seasonal temperature change look like? . df_temperature.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Months Code Months Year Code Year Unit Value Flag Flag Description . 0 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1961 | 1961 | °C | -0.751 | Fc | Calculated data | . 1 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1962 | 1962 | °C | 0.985 | Fc | Calculated data | . 2 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1963 | 1963 | °C | 1.931 | Fc | Calculated data | . 3 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1964 | 1964 | °C | -2.056 | Fc | Calculated data | . 4 ET | Temperature change | AFG | Afghanistan | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1965 | 1965 | °C | -0.669 | Fc | Calculated data | . df_temperature.groupby(&quot;Months&quot;)[&quot;Value&quot;].agg([&quot;sum&quot;,&quot;mean&quot;,&quot;max&quot;]) . sum mean max . Months . Dec–Jan–Feb 6113.952 | 0.467428 | 8.206 | . Jun–Jul–Aug 6951.271 | 0.531890 | 4.764 | . Mar–Apr–May 6872.110 | 0.525511 | 5.533 | . Meteorological year 6413.093 | 0.491651 | 5.328 | . Sep–Oct–Nov 5761.315 | 0.441108 | 6.084 | . plt.figure(figsize=(18, 12)) for i, (combi, df) in enumerate(df_temperature.groupby([&#39;Months&#39;])): ax = plt.subplot(6, 3, i+1, ymargin=0.5) ax.plot(df.Value) ax.set_title(combi) #if i == 6: break plt.tight_layout(h_pad=3.0) plt.suptitle(&#39;Seasonal Temperature Change&#39;, y=1.03) plt.show() . Seasonal Temperature Change . We can see that on each month has different maximum temperrature. DEC-Jan-Feb has the hottest temperature with 8.206 followed by Sept-Oct-Nov. | . How does this vary by continent? Particularly South America? . south_america_countries =[&#39;Brazil&#39;,&#39;Argentina&#39;,&#39;Chile&#39;,&#39;Colombia&#39;, &#39;Ecuador&#39;,&#39;Venezuela (Bolivarian Republic of)&#39;, &#39;Bolivia (Plurinational State of)&#39;,&#39;Guyana&#39;, &#39;Uruguay&#39;,&#39;Suriname&#39;, &#39;Paraguay&#39;,&#39;Aruba&#39;,&#39;Trinidad and Tobago&#39;] temperature_sa =df_temperature[df_temperature[&quot;Area&quot;].isin(south_america_countries)] temperature_sa.head() . Domain Code Domain Area Code (ISO3) Area Element Code Element Months Code Months Year Code Year Unit Value Flag Flag Description . 2700 ET | Temperature change | ARG | Argentina | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1961 | 1961 | °C | 0.035 | Fc | Calculated data | . 2701 ET | Temperature change | ARG | Argentina | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1962 | 1962 | °C | -0.144 | Fc | Calculated data | . 2702 ET | Temperature change | ARG | Argentina | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1963 | 1963 | °C | 0.552 | Fc | Calculated data | . 2703 ET | Temperature change | ARG | Argentina | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1964 | 1964 | °C | 0.052 | Fc | Calculated data | . 2704 ET | Temperature change | ARG | Argentina | 7271 | Temperature change | 7016 | Dec–Jan–Feb | 1965 | 1965 | °C | -0.034 | Fc | Calculated data | . temperature_sa.groupby([&quot;Area&quot;])[&quot;Value&quot;].agg([&quot;max&quot;,&quot;min&quot;]).plot(kind=&quot;bar&quot;,figsize=(12,8)) plt.ylabel(&quot;Temperature&quot;) . Text(0, 0.5, &#39;Temperature&#39;) . How about Meterological season temperature changes in South America? . temperature_sa= temperature_sa.groupby([&quot;Year&quot;,&quot;Months&quot;])[&quot;Value&quot;].mean().reset_index() plt.figure(figsize=(15, 10)) ax = sns.scatterplot(x=&#39;Year&#39;, y=&#39;Value&#39;, legend=&#39;full&#39;, hue=&#39;Months&#39;, data=temperature_sa, palette=sns.color_palette(&quot;Set1&quot;, n_colors=len(temperature_sa.Months.unique()))) max_value_per_year = temperature_sa.groupby(&#39;Year&#39;)[&#39;Value&#39;].max() sns.lineplot(data=max_value_per_year, ax=ax.axes, color=&#39;black&#39;) plt.ylabel(&quot;Temperature Change&quot;, fontsize=16) plt.xlabel(&quot;Year&quot;, fontsize=16) plt.axvspan(2013, 2016,alpha=0.15) plt.show() . Ultimately, there is an uptrend for temperature change in South America annually in which the peak is around 2013-2016. | . For joining this competition, see Z-Unlocked_Challenge1. There is a chance to visit Barcelona for Kaggle Competition. .",
            "url": "https://naiborhujosua.github.io/mlnotes_josua/2022/03/30/data-visualization-challenge.html",
            "relUrl": "/2022/03/30/data-visualization-challenge.html",
            "date": " • Mar 30, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Model Design using Pytorch",
            "content": "import torch.nn as nn import torch.nn.functional as F import torch from torch import optim . class SimpleNet(nn.Module): ## created layers as classattributes def __init__(self): ## call the base class to initialize params super(SimpleNet,self).__init__() self.fc1 = nn.Linear(2048,256) self.fc2 = nn.Linear(256,64) self.fc3 = nn.Linear(64,2) ## Required to define how the model process the parameters def forward(self,x): x = x.view(-1,2048) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = F.softmax(self.fc3(x),dim=1) return x . simplenet = SimpleNet() print(simplenet) . SimpleNet( (fc1): Linear(in_features=2048, out_features=256, bias=True) (fc2): Linear(in_features=256, out_features=64, bias=True) (fc3): Linear(in_features=64, out_features=2, bias=True) ) . nn.Module also supports for CNN, Dropout, and BatchNomarlization to implement in our model. . Training Loop . implemented training loop using LeNet5 model . class LeNet5(nn.Module): def __init__(self): super(LeNet5,self).__init__() self.conv1 = nn.Conv2d(3,6,5) self.conv2 = nn.Conv2d(6,16,5) self.fc1 = nn.Linear(16*5*5,120) self.fc2 = nn.Linear(120,84) self.fc3 = nn.Linear(84,10) def forward(self,x): x = F.max_pool2d(F.relu(self.conv1(x)),(2,2)) x = F.max_pool2d(F.relu(self.conv2(x)),2) x = x.view(-1,int(x.nelement()/x.shape[0])) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x device = (&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;) ##move to GPU model = LeNet5().to(device=device) . from torchvision.datasets import CIFAR10 train_data = CIFAR10(root=&quot;./train/&quot;,train=True,download=True) . Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz Extracting ./train/cifar-10-python.tar.gz to ./train/ . test_data = CIFAR10(root=&quot;./test/&quot;,train=False,download=True) . Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./test/cifar-10-python.tar.gz Extracting ./test/cifar-10-python.tar.gz to ./test/ . Transform the data . from torchvision import transforms train_transforms = transforms.Compose([ transforms.RandomCrop(32,padding=4), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize( mean = (0.4914,0.4822,0.4465), std = (0.2023,0.1994,0.2010))]) train_data = CIFAR10(root=&quot;./train/&quot;,train=True, download=True,transform=train_transforms) . Files already downloaded and verified . from torchvision import transforms test_transforms = transforms.Compose([ transforms.RandomCrop(32,padding=4), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize( mean = (0.4914,0.4822,0.4465), std = (0.2023,0.1994,0.2010))]) test_data = CIFAR10(root=&quot;./test/&quot;,train=False, download=True,transform=test_transforms) . Files already downloaded and verified . Data Batching using DataLoader . trainloader =torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True) . testloader =torch.utils.data.DataLoader(test_data, batch_size=16, shuffle=False) . criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(model.parameters(),lr=1e-2,momentum=0.9) N_EPOCHS = 10 for epoch in range(1,N_EPOCHS+1): epoch_loss = 0.0 for inputs,labels in trainloader: inputs = inputs.to(device) labels = labels.to(device) optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs,labels) loss.backward() optimizer.step() epoch_loss +=loss.item() print(f&quot;Epoch {epoch} Loss {epoch_loss/len(trainloader)}&quot;) . Epoch 1 Loss 1.8241477269363404 Epoch 2 Loss 1.6615231191253663 Epoch 3 Loss 1.6304866078948974 Epoch 4 Loss 1.6164952528762817 Epoch 5 Loss 1.5978561991500855 Epoch 6 Loss 1.5923947086524963 Epoch 7 Loss 1.5816101968955993 Epoch 8 Loss 1.591676569519043 Epoch 9 Loss 1.5898757279396056 Epoch 10 Loss 1.5873737773704528 . Validation . from torch.utils.data import random_split train_set,val_set = random_split(train_data,[40000,10000]) trainloader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True) valloader = torch.utils.data.DataLoader(val_set, batch_size=16, shuffle=True) print(len(trainloader),len(valloader)) . 2500 625 . model = LeNet5().to(device) criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(model.parameters(),lr=1e-2,momentum=0.9) . N_EPOCHS = 10 for epoch in range(1,N_EPOCHS+1): train_loss = 0.0 model.train() for inputs,labels in trainloader: inputs = inputs.to(device) labels = labels.to(device) optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs,labels) loss.backward() optimizer.step() epoch_loss +=loss.item() val_loss =0.0 model.eval() for inputs,labels in valloader: inputs = inputs.to(device) labels = labels.to(device) outputs = model(inputs) loss = criterion(outputs,labels) val_loss +=loss.item() print(f&quot;Epoch {epoch} Train Loss {epoch_loss/len(trainloader)} Val loss {val_loss/len(valloader)}&quot;) . Epoch 1 Train Loss 3.8346362232685087 Val loss 1.6857107292175293 Epoch 2 Train Loss 5.50487792634964 Val loss 1.6504140425682068 Epoch 3 Train Loss 7.115121179986 Val loss 1.5639411679267883 Epoch 4 Train Loss 8.702473026013374 Val loss 1.5383020911216736 Epoch 5 Train Loss 10.265977776813507 Val loss 1.5413660417556763 Epoch 6 Train Loss 11.820966996860504 Val loss 1.5524281386375427 Epoch 7 Train Loss 13.36783570830822 Val loss 1.6050877237319947 Epoch 8 Train Loss 14.901475507044792 Val loss 1.6089960625648498 Epoch 9 Train Loss 16.44660836327076 Val loss 1.573909682750702 Epoch 10 Train Loss 17.996182167482377 Val loss 1.588604866695404 . Validation occurs at every epoch after the training has been processed . During validation, the model is passed data which has not seen before. Only forward pass during validation. . Testing . num_correct = 0.0 for x_test_batch,y_test_batch in testloader: model.eval() y_test_batch = y_test_batch.to(device) x_test_batch = x_test_batch.to(device) y_pred_batch = model(x_test_batch) _,predicted = torch.max(y_pred_batch,1) num_correct +=(predicted==y_test_batch).float().sum() accuracy =num_correct / (len(testloader)*testloader.batch_size) print(f&quot;Test Accuracy {accuracy}&quot;) . Test Accuracy 0.44679999351501465 . Saving Models . torch.save(model.state_dict(),&quot;./lenet5_model.pt&quot;) model = LeNet5().to(device) model.load_state_dict(torch.load(&quot;./lenet5_model.pt&quot;)) . &lt;All keys matched successfully&gt; .",
            "url": "https://naiborhujosua.github.io/mlnotes_josua/2022/03/29/NN-for-new-user-of-Pytorch.html",
            "relUrl": "/2022/03/29/NN-for-new-user-of-Pytorch.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://naiborhujosua.github.io/mlnotes_josua/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Josua is a business development analyst who turns into a self-taught Data Scientist. His interests include statistical learning,predictive modeling, network experimentation, and causal inference. He loves running and it teaches him against giving up doing anything, even when implementing the Data Science lifecycle. . Apart from pursuing his passion for data science, he is keen on investing in the Indonesian Stock Exchange and Cryptocurrency. He has been running a full marathon in Jakarta Marathon in 2015 and Osaka Marathon in 2019. His next dreams are to run a marathon in TCS New York City Marathon and Virgin Money London Marathon. . For more, please reach out on LinkedIn! .",
          "url": "https://naiborhujosua.github.io/mlnotes_josua/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://naiborhujosua.github.io/mlnotes_josua/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}