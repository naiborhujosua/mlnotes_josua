{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421246a7-67a9-45ec-bf5b-dcf2407474a1",
   "metadata": {},
   "source": [
    "## Model Design using Pytorch \n",
    "This is a summary of building Neural network as a template for helping new users of pytroch.\n",
    "You can implement this for your project. \n",
    "All of the result just for experimentation. You can change based on your projects requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44325b94-68bf-4629-982c-3ac453eed408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch \n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583dd424-b178-4ee6-8c16-382df6e3d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    ## created layers as classattributes\n",
    "    def __init__(self):\n",
    "        ## call the base class to initialize params\n",
    "        super(SimpleNet,self).__init__()\n",
    "        self.fc1 = nn.Linear(2048,256)\n",
    "        self.fc2 = nn.Linear(256,64)\n",
    "        self.fc3 = nn.Linear(64,2)\n",
    "    \n",
    "    ## Required to define how the model process the parameters\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,2048)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x),dim=1)\n",
    "        return x \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2134174-9878-4338-9d7b-29ca231eed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "simplenet = SimpleNet()\n",
    "print(simplenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6322b-444f-4818-90cd-43a9c2979a50",
   "metadata": {},
   "source": [
    "nn.Module also supports for CNN, Dropout, and BatchNomarlization to implement in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f0f35-e767-494d-ae1c-f945d08241b3",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "implemented training loop using LeNet5 model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e0e021-2532-46c3-bf6b-ddd2f28e3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.view(-1,int(x.nelement()/x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "##move to GPU \n",
    "model = LeNet5().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce216a07-2b10-4a2f-9838-79d5adbb2f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767fe306390b4333a1396567401c15b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train/cifar-10-python.tar.gz to ./train/\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "train_data = CIFAR10(root=\"./train/\",train=True,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0128c441-51e3-45e1-a0b4-2344d8d06b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./test/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f020e8f8fd94112b964610792464cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./test/cifar-10-python.tar.gz to ./test/\n"
     ]
    }
   ],
   "source": [
    "test_data = CIFAR10(root=\"./test/\",train=False,download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea87b3-7208-46ea-b0f6-d3311e414981",
   "metadata": {},
   "source": [
    "## Transform the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9ca823e-007e-4e78-8dc7-a8091926845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = (0.4914,0.4822,0.4465),\n",
    "        std = (0.2023,0.1994,0.2010))])\n",
    "\n",
    "train_data = CIFAR10(root=\"./train/\",train=True,\n",
    "                     download=True,transform=train_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20fe0c17-ce2d-4ef6-9f31-849c232a0b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = (0.4914,0.4822,0.4465),\n",
    "        std = (0.2023,0.1994,0.2010))])\n",
    "\n",
    "test_data = CIFAR10(root=\"./test/\",train=False,\n",
    "                     download=True,transform=test_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f371ad4-977c-459f-a69c-3994299a5eaa",
   "metadata": {},
   "source": [
    "## Data Batching using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "895fe12e-102d-4c44-b6dd-651d7923d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader =torch.utils.data.DataLoader(train_data,\n",
    "                                         batch_size=16,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0a91b2c-05a4-40a4-aefc-65d4f22f89c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader  =torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size=16,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f296d3d-3716-42e6-a33f-108bff25675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1.8207738812637329\n",
      "Epoch 2 Loss 1.6673013194084167\n",
      "Epoch 3 Loss 1.611757234916687\n",
      "Epoch 4 Loss 1.588782156829834\n",
      "Epoch 5 Loss 1.5781982357215882\n",
      "Epoch 6 Loss 1.575931268749237\n",
      "Epoch 7 Loss 1.566828318157196\n",
      "Epoch 8 Loss 1.5608065349769593\n",
      "Epoch 9 Loss 1.5636185508155822\n",
      "Epoch 10 Loss 1.5685766509628296\n"
     ]
    }
   ],
   "source": [
    "## optimization \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=1e-2,momentum=0.9)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "for epoch in range(1,N_EPOCHS+1):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for inputs,labels in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss +=loss.item()\n",
    "    print(f\"Epoch {epoch} Loss {epoch_loss/len(trainloader)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805788b-26af-43c6-8208-61f6fb9a219c",
   "metadata": {},
   "source": [
    "## Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed3d1cf0-204a-402c-88b9-7e75ac3e9911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 625\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split \n",
    "train_set,val_set = random_split(train_data,[40000,10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(val_set,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=True)\n",
    "\n",
    "print(len(trainloader),len(valloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b68a8eaa-6fc6-4cd4-9447-440be621f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=1e-2,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c72191d-75c8-4f29-b7a8-06a55c462b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss 3.1996474461317064 Val loss 1.6014307223320008\n",
      "Epoch 2 Train Loss 4.802808263874054 Val loss 1.6740261289596559\n",
      "Epoch 3 Train Loss 6.413015327715874 Val loss 1.603927476119995\n",
      "Epoch 4 Train Loss 8.018378995585442 Val loss 1.697635841178894\n",
      "Epoch 5 Train Loss 9.63322612273693 Val loss 1.5807183632850648\n",
      "Epoch 6 Train Loss 11.2521382843256 Val loss 1.5649494188308717\n",
      "Epoch 7 Train Loss 12.86784440665245 Val loss 1.6468664051055908\n",
      "Epoch 8 Train Loss 14.477429402422905 Val loss 1.6350692648887635\n",
      "Epoch 9 Train Loss 16.108355063533782 Val loss 1.6147620951652526\n",
      "Epoch 10 Train Loss 17.732579513716697 Val loss 1.674453691291809\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "for epoch in range(1,N_EPOCHS+1):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs,labels in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss +=loss.item()\n",
    "        \n",
    "        \n",
    "    val_loss =0.0\n",
    "    model.eval()\n",
    "    for inputs,labels in valloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        val_loss +=loss.item()\n",
    "    print(f\"Epoch {epoch} Train Loss {epoch_loss/len(trainloader)} Val loss {val_loss/len(valloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e0580-048e-4a24-9f4a-0c4d62a66e09",
   "metadata": {},
   "source": [
    "Validation occurs at every epoch after the training has been processed \n",
    ". During validation, the model is passed data which has not seen before. Only forward pass during validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa423dc2-1395-44e4-a8a1-14ae0bf0cf5d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28f3068e-3f5a-46c4-ab21-49042781a391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.4056999981403351\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0 \n",
    "for x_test_batch,y_test_batch in testloader:\n",
    "    model.eval()\n",
    "    \n",
    "    y_test_batch = y_test_batch.to(device)\n",
    "    x_test_batch = x_test_batch.to(device)\n",
    "    y_pred_batch = model(x_test_batch)\n",
    "    _,predicted = torch.max(y_pred_batch,1)\n",
    "    num_correct +=(predicted==y_test_batch).float().sum()\n",
    "    \n",
    "accuracy =num_correct / (len(testloader)*testloader.batch_size)\n",
    "\n",
    "print(f\"Test Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca31a3-fa87-4722-bc57-6fe30802a11a",
   "metadata": {},
   "source": [
    "## Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c112b244-2d04-4fb2-bc64-d16da16d18a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(),\"./lenet5_model.pt\")\n",
    "model = LeNet5().to(device)\n",
    "model.load_state_dict(torch.load(\"./lenet5_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ace7dd-a25a-4aac-8695-b47bb63e61ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
